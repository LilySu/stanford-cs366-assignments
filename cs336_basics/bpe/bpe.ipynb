{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91e3865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import regex as re\n",
    "from typing import BinaryIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ca27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw many amazing things, like beautiful vases that were on display in a store. One day, Ben was walking through the store when he came across a very special vase. When Ben saw it he was amazed!  \n",
      "He said, “Wow, that is a really amazing vase! Can I buy it?” \n",
      "The shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends how amazing it is!”\n",
      "So Ben took the vase home and he was so proud of it! He called his friends over and showed them the amazing vase. All his friends thought the vase was beautiful and couldn't believe how lucky Ben was. \n",
      "And that's how Ben found an amazing vase in the store!\n",
      "<|endoftext|>\n",
      "Once upon a time, there was a reliable otter named Ollie. He lived in a river with his family. They all loved to play and swim together.\n",
      "One day, Ollie's mom said, \"Ollie, hurry and get some fish for dinner!\" Ollie swam fast to catch fish. He saw\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/TinyStoriesV2-GPT4-train.txt\", \"rb\") as f:\n",
    "    raw_data = f.read(1000).decode(\"utf-8\", errors=\"ignore\")\n",
    "        # Run pre-tokenization on your chunk and store the counts for each pre-token\n",
    "    print(raw_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27f7c060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token': 'some', 'start': 0, 'end': 4}\n",
      "{'token': ' text', 'start': 4, 'end': 9}\n",
      "{'token': ' that', 'start': 9, 'end': 14}\n",
      "{'token': ' i', 'start': 14, 'end': 16}\n",
      "{'token': \"'ll\", 'start': 16, 'end': 19}\n",
      "{'token': ' pre', 'start': 19, 'end': 23}\n",
      "{'token': '-', 'start': 23, 'end': 24}\n",
      "{'token': 'tokenize', 'start': 24, 'end': 32}\n"
     ]
    }
   ],
   "source": [
    "# splitting on whitespace\n",
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "text = \"some text that i'll pre-tokenize\"\n",
    "\n",
    "for m in re.finditer(PAT, text):\n",
    "    print({\n",
    "        \"token\": m.group(),\n",
    "        \"start\": m.start(),\n",
    "        \"end\": m.end()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "161cd3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 8,\n",
       " 'Once': 2,\n",
       " ' upon': 2,\n",
       " ' a': 8,\n",
       " ' time': 2,\n",
       " ' there': 2,\n",
       " ' was': 7,\n",
       " ' little': 1,\n",
       " ' boy': 1,\n",
       " ' named': 2,\n",
       " ' Ben': 7,\n",
       " '.': 11,\n",
       " ' loved': 2,\n",
       " ' to': 3,\n",
       " ' explore': 1,\n",
       " ' the': 6,\n",
       " ' world': 1,\n",
       " ' around': 1,\n",
       " ' him': 1,\n",
       " ' He': 4,\n",
       " ' saw': 3,\n",
       " ' many': 1,\n",
       " ' amazing': 5,\n",
       " ' things': 1,\n",
       " ',': 9,\n",
       " ' like': 1,\n",
       " ' beautiful': 2,\n",
       " ' vases': 1,\n",
       " ' that': 3,\n",
       " ' were': 1,\n",
       " ' on': 1,\n",
       " ' display': 1,\n",
       " ' in': 3,\n",
       " ' store': 3,\n",
       " ' One': 1,\n",
       " ' day': 2,\n",
       " ' walking': 1,\n",
       " ' through': 1,\n",
       " ' when': 1,\n",
       " ' he': 3,\n",
       " ' came': 1,\n",
       " ' across': 1,\n",
       " ' very': 1,\n",
       " ' special': 1,\n",
       " ' vase': 6,\n",
       " ' When': 1,\n",
       " ' it': 5,\n",
       " ' amazed': 1,\n",
       " '!': 4,\n",
       " '  ': 1,\n",
       " 'He': 1,\n",
       " ' said': 3,\n",
       " ' “': 2,\n",
       " 'Wow': 1,\n",
       " ' is': 2,\n",
       " ' really': 1,\n",
       " ' Can': 1,\n",
       " ' I': 1,\n",
       " ' buy': 1,\n",
       " '?”': 1,\n",
       " ' ': 2,\n",
       " 'The': 1,\n",
       " ' shopkeeper': 1,\n",
       " ' smiled': 1,\n",
       " ' and': 7,\n",
       " 'Of': 1,\n",
       " ' course': 1,\n",
       " ' you': 1,\n",
       " ' can': 2,\n",
       " ' You': 1,\n",
       " ' take': 1,\n",
       " ' home': 2,\n",
       " ' show': 1,\n",
       " ' all': 2,\n",
       " ' your': 1,\n",
       " ' friends': 3,\n",
       " ' how': 3,\n",
       " '!”': 1,\n",
       " 'So': 1,\n",
       " ' took': 1,\n",
       " ' so': 1,\n",
       " ' proud': 1,\n",
       " ' of': 1,\n",
       " ' called': 1,\n",
       " ' his': 3,\n",
       " ' over': 1,\n",
       " ' showed': 1,\n",
       " ' them': 1,\n",
       " ' All': 1,\n",
       " ' thought': 1,\n",
       " ' couldn': 1,\n",
       " \"'t\": 1,\n",
       " ' believe': 1,\n",
       " ' lucky': 1,\n",
       " 'And': 1,\n",
       " \"'s\": 2,\n",
       " ' found': 1,\n",
       " ' an': 1,\n",
       " ' reliable': 1,\n",
       " ' otter': 1,\n",
       " ' Ollie': 3,\n",
       " ' lived': 1,\n",
       " ' river': 1,\n",
       " ' with': 1,\n",
       " ' family': 1,\n",
       " ' They': 1,\n",
       " ' play': 1,\n",
       " ' swim': 1,\n",
       " ' together': 1,\n",
       " 'One': 1,\n",
       " ' mom': 1,\n",
       " ' \"': 1,\n",
       " 'Ollie': 1,\n",
       " ' hurry': 1,\n",
       " ' get': 1,\n",
       " ' some': 1,\n",
       " ' fish': 2,\n",
       " ' for': 1,\n",
       " ' dinner': 1,\n",
       " '!\"': 1,\n",
       " ' swam': 1,\n",
       " ' fast': 1,\n",
       " ' catch': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import regex as re\n",
    "\n",
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "compiled_pattern = re.compile(PAT)\n",
    "\n",
    "def get_token_frequencies(text, pattern, special_tokens=None):\n",
    "    \"\"\"\n",
    "    Takes text and a compiled regex pattern.\n",
    "    Returns a frequency table: { 'token': count, ... }\n",
    "    \"\"\"\n",
    "    stats = {}\n",
    "    \n",
    "    # Step 1: Split on special tokens if provided\n",
    "    if special_tokens:\n",
    "        # Build pattern: escape each special token and join with |\n",
    "        split_pattern = \"|\".join(re.escape(token) for token in special_tokens)\n",
    "        # Split the text, keeping only non-empty chunks\n",
    "        chunks = [chunk for chunk in re.split(split_pattern, text) if chunk]\n",
    "    else:\n",
    "        chunks = [text]\n",
    "    \n",
    "    # Step 2: Pre-tokenize each chunk separately\n",
    "    for chunk in chunks:\n",
    "        # iterate using finditer (memory efficient)\n",
    "        for match in pattern.finditer(chunk):\n",
    "            # Extract the actual string matched\n",
    "            token = match.group()\n",
    "            \n",
    "            # Manual counting logic\n",
    "            if token in stats:\n",
    "                stats[token] += 1\n",
    "            else:\n",
    "                stats[token] = 1\n",
    "            \n",
    "    return stats\n",
    "\n",
    "# Usage for TinyStories:\n",
    "special_tokens = [\"<|endoftext|>\"]\n",
    "frequency_table = get_token_frequencies(raw_data, compiled_pattern, special_tokens)\n",
    "frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f3a0a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 8, 'Once': 2, ' upon': 2, ' a': 8, ' time': 2, ' there': 2, ' was': 7, ' little': 1, ' boy': 1, ' named': 2, ' Ben': 7, '.': 11, ' loved': 2, ' to': 3, ' explore': 1, ' the': 6, ' world': 1, ' around': 1, ' him': 1, ' He': 4, ' saw': 3, ' many': 1, ' amazing': 5, ' things': 1, ',': 9, ' like': 1, ' beautiful': 2, ' vases': 1, ' that': 3, ' were': 1, ' on': 1, ' display': 1, ' in': 3, ' store': 3, ' One': 1, ' day': 2, ' walking': 1, ' through': 1, ' when': 1, ' he': 3, ' came': 1, ' across': 1, ' very': 1, ' special': 1, ' vase': 6, ' When': 1, ' it': 5, ' amazed': 1, '!': 4, '  ': 1, 'He': 1, ' said': 3, ' “': 2, 'Wow': 1, ' is': 2, ' really': 1, ' Can': 1, ' I': 1, ' buy': 1, '?”': 1, ' ': 2, 'The': 1, ' shopkeeper': 1, ' smiled': 1, ' and': 7, 'Of': 1, ' course': 1, ' you': 1, ' can': 2, ' You': 1, ' take': 1, ' home': 2, ' show': 1, ' all': 2, ' your': 1, ' friends': 3, ' how': 3, '!”': 1, 'So': 1, ' took': 1, ' so': 1, ' proud': 1, ' of': 1, ' called': 1, ' his': 3, ' over': 1, ' showed': 1, ' them': 1, ' All': 1, ' thought': 1, ' couldn': 1, \"'t\": 1, ' believe': 1, ' lucky': 1, 'And': 1, \"'s\": 2, ' found': 1, ' an': 1, '<|': 1, 'endoftext': 1, '|>': 1, ' reliable': 1, ' otter': 1, ' Ollie': 3, ' lived': 1, ' river': 1, ' with': 1, ' family': 1, ' They': 1, ' play': 1, ' swim': 1, ' together': 1, 'One': 1, ' mom': 1, ' \"': 1, 'Ollie': 1, ' hurry': 1, ' get': 1, ' some': 1, ' fish': 2, ' for': 1, ' dinner': 1, '!\"': 1, ' swam': 1, ' fast': 1, ' catch': 1}\n"
     ]
    }
   ],
   "source": [
    "compiled_pattern = re.compile(PAT, re.IGNORECASE)\n",
    "\n",
    "# Run the function\n",
    "frequency_table = get_token_frequencies(raw_data, compiled_pattern)\n",
    "\n",
    "# Output the table\n",
    "print(frequency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e879231e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('.',): 11\n",
      "(',',): 9\n",
      "('\\n',): 8\n",
      "(' ', 'a'): 8\n",
      "(' ', 'w', 'a', 's'): 7\n",
      "(' ', 'B', 'e', 'n'): 7\n",
      "(' ', 'a', 'n', 'd'): 7\n",
      "(' ', 't', 'h', 'e'): 6\n",
      "(' ', 'v', 'a', 's', 'e'): 6\n",
      "(' ', 'a', 'm', 'a', 'z', 'i', 'n', 'g'): 5\n",
      "(' ', 'i', 't'): 5\n",
      "(' ', 'H', 'e'): 4\n",
      "('!',): 4\n",
      "(' ', 't', 'o'): 3\n",
      "(' ', 's', 'a', 'w'): 3\n",
      "(' ', 't', 'h', 'a', 't'): 3\n",
      "(' ', 'i', 'n'): 3\n",
      "(' ', 's', 't', 'o', 'r', 'e'): 3\n",
      "(' ', 'h', 'e'): 3\n",
      "(' ', 's', 'a', 'i', 'd'): 3\n",
      "(' ', 'f', 'r', 'i', 'e', 'n', 'd', 's'): 3\n",
      "(' ', 'h', 'o', 'w'): 3\n",
      "(' ', 'h', 'i', 's'): 3\n",
      "(' ', 'O', 'l', 'l', 'i', 'e'): 3\n",
      "('O', 'n', 'c', 'e'): 2\n",
      "(' ', 'u', 'p', 'o', 'n'): 2\n",
      "(' ', 't', 'i', 'm', 'e'): 2\n",
      "(' ', 't', 'h', 'e', 'r', 'e'): 2\n",
      "(' ', 'n', 'a', 'm', 'e', 'd'): 2\n",
      "(' ', 'l', 'o', 'v', 'e', 'd'): 2\n",
      "(' ', 'b', 'e', 'a', 'u', 't', 'i', 'f', 'u', 'l'): 2\n",
      "(' ', 'd', 'a', 'y'): 2\n",
      "(' ', '“'): 2\n",
      "(' ', 'i', 's'): 2\n",
      "(' ',): 2\n",
      "(' ', 'c', 'a', 'n'): 2\n",
      "(' ', 'h', 'o', 'm', 'e'): 2\n",
      "(' ', 'a', 'l', 'l'): 2\n",
      "(\"'\", 's'): 2\n",
      "(' ', 'f', 'i', 's', 'h'): 2\n",
      "(' ', 'l', 'i', 't', 't', 'l', 'e'): 1\n",
      "(' ', 'b', 'o', 'y'): 1\n",
      "(' ', 'e', 'x', 'p', 'l', 'o', 'r', 'e'): 1\n",
      "(' ', 'w', 'o', 'r', 'l', 'd'): 1\n",
      "(' ', 'a', 'r', 'o', 'u', 'n', 'd'): 1\n",
      "(' ', 'h', 'i', 'm'): 1\n",
      "(' ', 'm', 'a', 'n', 'y'): 1\n",
      "(' ', 't', 'h', 'i', 'n', 'g', 's'): 1\n",
      "(' ', 'l', 'i', 'k', 'e'): 1\n",
      "(' ', 'v', 'a', 's', 'e', 's'): 1\n",
      "(' ', 'w', 'e', 'r', 'e'): 1\n",
      "(' ', 'o', 'n'): 1\n",
      "(' ', 'd', 'i', 's', 'p', 'l', 'a', 'y'): 1\n",
      "(' ', 'O', 'n', 'e'): 1\n",
      "(' ', 'w', 'a', 'l', 'k', 'i', 'n', 'g'): 1\n",
      "(' ', 't', 'h', 'r', 'o', 'u', 'g', 'h'): 1\n",
      "(' ', 'w', 'h', 'e', 'n'): 1\n",
      "(' ', 'c', 'a', 'm', 'e'): 1\n",
      "(' ', 'a', 'c', 'r', 'o', 's', 's'): 1\n",
      "(' ', 'v', 'e', 'r', 'y'): 1\n",
      "(' ', 's', 'p', 'e', 'c', 'i', 'a', 'l'): 1\n",
      "(' ', 'W', 'h', 'e', 'n'): 1\n",
      "(' ', 'a', 'm', 'a', 'z', 'e', 'd'): 1\n",
      "(' ', ' '): 1\n",
      "('H', 'e'): 1\n",
      "('W', 'o', 'w'): 1\n",
      "(' ', 'r', 'e', 'a', 'l', 'l', 'y'): 1\n",
      "(' ', 'C', 'a', 'n'): 1\n",
      "(' ', 'I'): 1\n",
      "(' ', 'b', 'u', 'y'): 1\n",
      "('?', '”'): 1\n",
      "('T', 'h', 'e'): 1\n",
      "(' ', 's', 'h', 'o', 'p', 'k', 'e', 'e', 'p', 'e', 'r'): 1\n",
      "(' ', 's', 'm', 'i', 'l', 'e', 'd'): 1\n",
      "('O', 'f'): 1\n",
      "(' ', 'c', 'o', 'u', 'r', 's', 'e'): 1\n",
      "(' ', 'y', 'o', 'u'): 1\n",
      "(' ', 'Y', 'o', 'u'): 1\n",
      "(' ', 't', 'a', 'k', 'e'): 1\n",
      "(' ', 's', 'h', 'o', 'w'): 1\n",
      "(' ', 'y', 'o', 'u', 'r'): 1\n",
      "('!', '”'): 1\n",
      "('S', 'o'): 1\n",
      "(' ', 't', 'o', 'o', 'k'): 1\n",
      "(' ', 's', 'o'): 1\n",
      "(' ', 'p', 'r', 'o', 'u', 'd'): 1\n",
      "(' ', 'o', 'f'): 1\n",
      "(' ', 'c', 'a', 'l', 'l', 'e', 'd'): 1\n",
      "(' ', 'o', 'v', 'e', 'r'): 1\n",
      "(' ', 's', 'h', 'o', 'w', 'e', 'd'): 1\n",
      "(' ', 't', 'h', 'e', 'm'): 1\n",
      "(' ', 'A', 'l', 'l'): 1\n",
      "(' ', 't', 'h', 'o', 'u', 'g', 'h', 't'): 1\n",
      "(' ', 'c', 'o', 'u', 'l', 'd', 'n'): 1\n",
      "(\"'\", 't'): 1\n",
      "(' ', 'b', 'e', 'l', 'i', 'e', 'v', 'e'): 1\n",
      "(' ', 'l', 'u', 'c', 'k', 'y'): 1\n",
      "('A', 'n', 'd'): 1\n",
      "(' ', 'f', 'o', 'u', 'n', 'd'): 1\n",
      "(' ', 'a', 'n'): 1\n",
      "('<', '|'): 1\n",
      "('e', 'n', 'd', 'o', 'f', 't', 'e', 'x', 't'): 1\n",
      "('|', '>'): 1\n",
      "(' ', 'r', 'e', 'l', 'i', 'a', 'b', 'l', 'e'): 1\n",
      "(' ', 'o', 't', 't', 'e', 'r'): 1\n",
      "(' ', 'l', 'i', 'v', 'e', 'd'): 1\n",
      "(' ', 'r', 'i', 'v', 'e', 'r'): 1\n",
      "(' ', 'w', 'i', 't', 'h'): 1\n",
      "(' ', 'f', 'a', 'm', 'i', 'l', 'y'): 1\n",
      "(' ', 'T', 'h', 'e', 'y'): 1\n",
      "(' ', 'p', 'l', 'a', 'y'): 1\n",
      "(' ', 's', 'w', 'i', 'm'): 1\n",
      "(' ', 't', 'o', 'g', 'e', 't', 'h', 'e', 'r'): 1\n",
      "('O', 'n', 'e'): 1\n",
      "(' ', 'm', 'o', 'm'): 1\n",
      "(' ', '\"'): 1\n",
      "('O', 'l', 'l', 'i', 'e'): 1\n",
      "(' ', 'h', 'u', 'r', 'r', 'y'): 1\n",
      "(' ', 'g', 'e', 't'): 1\n",
      "(' ', 's', 'o', 'm', 'e'): 1\n",
      "(' ', 'f', 'o', 'r'): 1\n",
      "(' ', 'd', 'i', 'n', 'n', 'e', 'r'): 1\n",
      "('!', '\"'): 1\n",
      "(' ', 's', 'w', 'a', 'm'): 1\n",
      "(' ', 'f', 'a', 's', 't'): 1\n",
      "(' ', 'c', 'a', 't', 'c', 'h'): 1\n"
     ]
    }
   ],
   "source": [
    "vocab = {}\n",
    "for token, count in frequency_table.items():\n",
    "    vocab[tuple(list(token))] = count\n",
    "\n",
    "for token, count in sorted(vocab.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{token}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89c1cefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pair frequencies:\n",
      "(' ', 'a'): 26\n",
      "(' ', 't'): 23\n",
      "(' ', 's'): 18\n",
      "('t', 'h'): 17\n",
      "('h', 'e'): 17\n",
      "('a', 's'): 15\n",
      "('n', 'd'): 14\n",
      "('e', 'n'): 13\n",
      "(' ', 'h'): 13\n",
      "(' ', 'w'): 12\n",
      "('a', 'n'): 12\n",
      "('a', 'm'): 11\n",
      "('i', 'n'): 11\n",
      "('e', 'r'): 10\n",
      "('o', 'u'): 10\n",
      "(' ', 'i'): 10\n",
      "('r', 'e'): 9\n",
      "('w', 'a'): 9\n",
      "('l', 'i'): 9\n",
      "('e', 'd'): 9\n",
      "('l', 'l'): 9\n",
      "('h', 'o'): 9\n",
      "(' ', 'f'): 9\n",
      "('m', 'e'): 8\n",
      "('t', 'o'): 8\n",
      "(' ', 'v'): 8\n",
      "('s', 'e'): 8\n",
      "('i', 's'): 8\n",
      "('i', 'e'): 8\n",
      "('i', 't'): 7\n",
      "(' ', 'B'): 7\n",
      "('B', 'e'): 7\n",
      "('v', 'e'): 7\n",
      "('m', 'a'): 7\n",
      "('n', 'g'): 7\n",
      "('v', 'a'): 7\n",
      "(' ', 'c'): 7\n",
      "(' ', 'l'): 6\n",
      "('o', 'r'): 6\n",
      "('s', 'a'): 6\n",
      "('a', 'z'): 6\n",
      "('a', 'l'): 6\n",
      "('o', 'w'): 6\n",
      "(' ', 'b'): 5\n",
      "('h', 'i'): 5\n",
      "('H', 'e'): 5\n",
      "('z', 'i'): 5\n",
      "('c', 'a'): 5\n",
      "('s', 'h'): 5\n",
      "('O', 'n'): 4\n",
      "('t', 'i'): 4\n",
      "('i', 'm'): 4\n",
      "('l', 'e'): 4\n",
      "('r', 'o'): 4\n",
      "(' ', 'H'): 4\n",
      "('a', 't'): 4\n",
      "(' ', 'o'): 4\n",
      "(' ', 'd'): 4\n",
      "('a', 'y'): 4\n",
      "('s', 't'): 4\n",
      "(' ', 'O'): 4\n",
      "('o', 'm'): 4\n",
      "('r', 'i'): 4\n",
      "('O', 'l'): 4\n",
      "('o', 'n'): 3\n",
      "('l', 'o'): 3\n",
      "('o', 'v'): 3\n",
      "('p', 'l'): 3\n",
      "('a', 'w'): 3\n",
      "('k', 'e'): 3\n",
      "('b', 'e'): 3\n",
      "('e', 'a'): 3\n",
      "('u', 'l'): 3\n",
      "('h', 'a'): 3\n",
      "('n', 'e'): 3\n",
      "('a', 'i'): 3\n",
      "('i', 'd'): 3\n",
      "(' ', 'r'): 3\n",
      "('u', 'r'): 3\n",
      "('f', 'r'): 3\n",
      "('d', 's'): 3\n",
      "('n', 'c'): 2\n",
      "('c', 'e'): 2\n",
      "(' ', 'u'): 2\n",
      "('u', 'p'): 2\n",
      "('p', 'o'): 2\n",
      "('t', 't'): 2\n",
      "(' ', 'n'): 2\n",
      "('n', 'a'): 2\n",
      "('e', 'x'): 2\n",
      "('l', 'd'): 2\n",
      "('u', 'n'): 2\n",
      "(' ', 'm'): 2\n",
      "('a', 'u'): 2\n",
      "('u', 't'): 2\n",
      "('i', 'f'): 2\n",
      "('f', 'u'): 2\n",
      "('w', 'e'): 2\n",
      "('d', 'i'): 2\n",
      "('s', 'p'): 2\n",
      "('l', 'a'): 2\n",
      "('d', 'a'): 2\n",
      "('u', 'g'): 2\n",
      "('g', 'h'): 2\n",
      "('r', 'y'): 2\n",
      "('p', 'e'): 2\n",
      "('i', 'a'): 2\n",
      "(' ', '“'): 2\n",
      "('l', 'y'): 2\n",
      "('T', 'h'): 2\n",
      "('m', 'i'): 2\n",
      "('i', 'l'): 2\n",
      "('c', 'o'): 2\n",
      "(' ', 'y'): 2\n",
      "('y', 'o'): 2\n",
      "('s', 'o'): 2\n",
      "(' ', 'p'): 2\n",
      "('o', 'f'): 2\n",
      "('e', 'l'): 2\n",
      "(\"'\", 's'): 2\n",
      "('f', 'o'): 2\n",
      "('t', 'e'): 2\n",
      "('i', 'v'): 2\n",
      "('w', 'i'): 2\n",
      "('f', 'a'): 2\n",
      "('s', 'w'): 2\n",
      "('g', 'e'): 2\n",
      "('e', 't'): 2\n",
      "('f', 'i'): 2\n",
      "('t', 'l'): 1\n",
      "('b', 'o'): 1\n",
      "('o', 'y'): 1\n",
      "(' ', 'e'): 1\n",
      "('x', 'p'): 1\n",
      "('w', 'o'): 1\n",
      "('r', 'l'): 1\n",
      "('a', 'r'): 1\n",
      "('n', 'y'): 1\n",
      "('g', 's'): 1\n",
      "('i', 'k'): 1\n",
      "('e', 's'): 1\n",
      "('l', 'k'): 1\n",
      "('k', 'i'): 1\n",
      "('h', 'r'): 1\n",
      "('w', 'h'): 1\n",
      "('a', 'c'): 1\n",
      "('c', 'r'): 1\n",
      "('o', 's'): 1\n",
      "('s', 's'): 1\n",
      "('e', 'c'): 1\n",
      "('c', 'i'): 1\n",
      "(' ', 'W'): 1\n",
      "('W', 'h'): 1\n",
      "('z', 'e'): 1\n",
      "(' ', ' '): 1\n",
      "('W', 'o'): 1\n",
      "(' ', 'C'): 1\n",
      "('C', 'a'): 1\n",
      "(' ', 'I'): 1\n",
      "('b', 'u'): 1\n",
      "('u', 'y'): 1\n",
      "('?', '”'): 1\n",
      "('o', 'p'): 1\n",
      "('p', 'k'): 1\n",
      "('e', 'e'): 1\n",
      "('e', 'p'): 1\n",
      "('s', 'm'): 1\n",
      "('O', 'f'): 1\n",
      "('r', 's'): 1\n",
      "(' ', 'Y'): 1\n",
      "('Y', 'o'): 1\n",
      "('t', 'a'): 1\n",
      "('a', 'k'): 1\n",
      "('!', '”'): 1\n",
      "('S', 'o'): 1\n",
      "('o', 'o'): 1\n",
      "('o', 'k'): 1\n",
      "('p', 'r'): 1\n",
      "('u', 'd'): 1\n",
      "('e', 'm'): 1\n",
      "(' ', 'A'): 1\n",
      "('A', 'l'): 1\n",
      "('h', 't'): 1\n",
      "('d', 'n'): 1\n",
      "(\"'\", 't'): 1\n",
      "('e', 'v'): 1\n",
      "('l', 'u'): 1\n",
      "('u', 'c'): 1\n",
      "('c', 'k'): 1\n",
      "('k', 'y'): 1\n",
      "('A', 'n'): 1\n",
      "('<', '|'): 1\n",
      "('d', 'o'): 1\n",
      "('f', 't'): 1\n",
      "('x', 't'): 1\n",
      "('|', '>'): 1\n",
      "('a', 'b'): 1\n",
      "('b', 'l'): 1\n",
      "('o', 't'): 1\n",
      "(' ', 'T'): 1\n",
      "('e', 'y'): 1\n",
      "('o', 'g'): 1\n",
      "('m', 'o'): 1\n",
      "(' ', '\"'): 1\n",
      "('h', 'u'): 1\n",
      "('r', 'r'): 1\n",
      "(' ', 'g'): 1\n",
      "('n', 'n'): 1\n",
      "('!', '\"'): 1\n",
      "('t', 'c'): 1\n",
      "('c', 'h'): 1\n"
     ]
    }
   ],
   "source": [
    "def get_pair_frequencies(vocab):\n",
    "    \"\"\"\n",
    "    Given a vocab dict like {('l','o','w'): 5, ('l','o','w','e','r'): 2}\n",
    "    Returns pair counts like {('l','o'): 7, ('o','w'): 7, ('w','e'): 2, ...}\n",
    "    \"\"\"\n",
    "    pairs = {}\n",
    "    \n",
    "    # Loop through each token and its frequency\n",
    "    for token, freq in vocab.items():\n",
    "        # Look at consecutive pairs in this token\n",
    "        # Example: ('l','o','w') → pairs are ('l','o') and ('o','w')\n",
    "        for i in range(len(token) - 1):\n",
    "            # Get pair at position i\n",
    "            pair = (token[i], token[i + 1])\n",
    "            \n",
    "            # Add this pair's count (weighted by token frequency)\n",
    "            if pair in pairs:\n",
    "                pairs[pair] += freq\n",
    "            else:\n",
    "                pairs[pair] = freq\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "# Test it!\n",
    "pair_freq = get_pair_frequencies(frequency_table)\n",
    "print(\"\\nPair frequencies:\")\n",
    "for pair, count in sorted(pair_freq.items(), key=lambda x: -x[1]):  # Sort by frequency\n",
    "    print(f\"{pair}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124f4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_pair(pair_frequencies):\n",
    "    \"\"\"\n",
    "    Returns the pair with highest frequency.\n",
    "    In case of tie, returns lexicographically greater pair.\n",
    "    \"\"\"\n",
    "    if not pair_frequencies:\n",
    "        return None\n",
    "    \n",
    "    # Find the maximum frequency\n",
    "    max_freq = max(pair_frequencies.values())\n",
    "    \n",
    "    # Get all pairs with that frequency\n",
    "    top_pairs = [pair for pair, freq in pair_frequencies.items() if freq == max_freq]\n",
    "    \n",
    "    # Return the lexicographically greatest one\n",
    "    # max() on tuples compares element by element\n",
    "    return max(top_pairs)\n",
    "\n",
    "# Test it\n",
    "best_pair = get_best_pair(pair_freq)\n",
    "print(f\"\\nBest pair to merge: {best_pair}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dc18cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before merge: {('\\n',): 8, ('O', 'n', 'c', 'e'): 2, (' ', 'u', 'p', 'o', 'n'): 2, (' ', 'a'): 8, (' ', 't', 'i', 'm', 'e'): 2, (' ', 't', 'h', 'e', 'r', 'e'): 2, (' ', 'w', 'a', 's'): 7, (' ', 'l', 'i', 't', 't', 'l', 'e'): 1, (' ', 'b', 'o', 'y'): 1, (' ', 'n', 'a', 'm', 'e', 'd'): 2, (' ', 'B', 'e', 'n'): 7, ('.',): 11, (' ', 'l', 'o', 'v', 'e', 'd'): 2, (' ', 't', 'o'): 3, (' ', 'e', 'x', 'p', 'l', 'o', 'r', 'e'): 1, (' ', 't', 'h', 'e'): 6, (' ', 'w', 'o', 'r', 'l', 'd'): 1, (' ', 'a', 'r', 'o', 'u', 'n', 'd'): 1, (' ', 'h', 'i', 'm'): 1, (' ', 'H', 'e'): 4, (' ', 's', 'a', 'w'): 3, (' ', 'm', 'a', 'n', 'y'): 1, (' ', 'a', 'm', 'a', 'z', 'i', 'n', 'g'): 5, (' ', 't', 'h', 'i', 'n', 'g', 's'): 1, (',',): 9, (' ', 'l', 'i', 'k', 'e'): 1, (' ', 'b', 'e', 'a', 'u', 't', 'i', 'f', 'u', 'l'): 2, (' ', 'v', 'a', 's', 'e', 's'): 1, (' ', 't', 'h', 'a', 't'): 3, (' ', 'w', 'e', 'r', 'e'): 1, (' ', 'o', 'n'): 1, (' ', 'd', 'i', 's', 'p', 'l', 'a', 'y'): 1, (' ', 'i', 'n'): 3, (' ', 's', 't', 'o', 'r', 'e'): 3, (' ', 'O', 'n', 'e'): 1, (' ', 'd', 'a', 'y'): 2, (' ', 'w', 'a', 'l', 'k', 'i', 'n', 'g'): 1, (' ', 't', 'h', 'r', 'o', 'u', 'g', 'h'): 1, (' ', 'w', 'h', 'e', 'n'): 1, (' ', 'h', 'e'): 3, (' ', 'c', 'a', 'm', 'e'): 1, (' ', 'a', 'c', 'r', 'o', 's', 's'): 1, (' ', 'v', 'e', 'r', 'y'): 1, (' ', 's', 'p', 'e', 'c', 'i', 'a', 'l'): 1, (' ', 'v', 'a', 's', 'e'): 6, (' ', 'W', 'h', 'e', 'n'): 1, (' ', 'i', 't'): 5, (' ', 'a', 'm', 'a', 'z', 'e', 'd'): 1, ('!',): 4, (' ', ' '): 1, ('H', 'e'): 1, (' ', 's', 'a', 'i', 'd'): 3, (' ', '“'): 2, ('W', 'o', 'w'): 1, (' ', 'i', 's'): 2, (' ', 'r', 'e', 'a', 'l', 'l', 'y'): 1, (' ', 'C', 'a', 'n'): 1, (' ', 'I'): 1, (' ', 'b', 'u', 'y'): 1, ('?', '”'): 1, (' ',): 2, ('T', 'h', 'e'): 1, (' ', 's', 'h', 'o', 'p', 'k', 'e', 'e', 'p', 'e', 'r'): 1, (' ', 's', 'm', 'i', 'l', 'e', 'd'): 1, (' ', 'a', 'n', 'd'): 7, ('O', 'f'): 1, (' ', 'c', 'o', 'u', 'r', 's', 'e'): 1, (' ', 'y', 'o', 'u'): 1, (' ', 'c', 'a', 'n'): 2, (' ', 'Y', 'o', 'u'): 1, (' ', 't', 'a', 'k', 'e'): 1, (' ', 'h', 'o', 'm', 'e'): 2, (' ', 's', 'h', 'o', 'w'): 1, (' ', 'a', 'l', 'l'): 2, (' ', 'y', 'o', 'u', 'r'): 1, (' ', 'f', 'r', 'i', 'e', 'n', 'd', 's'): 3, (' ', 'h', 'o', 'w'): 3, ('!', '”'): 1, ('S', 'o'): 1, (' ', 't', 'o', 'o', 'k'): 1, (' ', 's', 'o'): 1, (' ', 'p', 'r', 'o', 'u', 'd'): 1, (' ', 'o', 'f'): 1, (' ', 'c', 'a', 'l', 'l', 'e', 'd'): 1, (' ', 'h', 'i', 's'): 3, (' ', 'o', 'v', 'e', 'r'): 1, (' ', 's', 'h', 'o', 'w', 'e', 'd'): 1, (' ', 't', 'h', 'e', 'm'): 1, (' ', 'A', 'l', 'l'): 1, (' ', 't', 'h', 'o', 'u', 'g', 'h', 't'): 1, (' ', 'c', 'o', 'u', 'l', 'd', 'n'): 1, (\"'\", 't'): 1, (' ', 'b', 'e', 'l', 'i', 'e', 'v', 'e'): 1, (' ', 'l', 'u', 'c', 'k', 'y'): 1, ('A', 'n', 'd'): 1, (\"'\", 's'): 2, (' ', 'f', 'o', 'u', 'n', 'd'): 1, (' ', 'a', 'n'): 1, ('<', '|'): 1, ('e', 'n', 'd', 'o', 'f', 't', 'e', 'x', 't'): 1, ('|', '>'): 1, (' ', 'r', 'e', 'l', 'i', 'a', 'b', 'l', 'e'): 1, (' ', 'o', 't', 't', 'e', 'r'): 1, (' ', 'O', 'l', 'l', 'i', 'e'): 3, (' ', 'l', 'i', 'v', 'e', 'd'): 1, (' ', 'r', 'i', 'v', 'e', 'r'): 1, (' ', 'w', 'i', 't', 'h'): 1, (' ', 'f', 'a', 'm', 'i', 'l', 'y'): 1, (' ', 'T', 'h', 'e', 'y'): 1, (' ', 'p', 'l', 'a', 'y'): 1, (' ', 's', 'w', 'i', 'm'): 1, (' ', 't', 'o', 'g', 'e', 't', 'h', 'e', 'r'): 1, ('O', 'n', 'e'): 1, (' ', 'm', 'o', 'm'): 1, (' ', '\"'): 1, ('O', 'l', 'l', 'i', 'e'): 1, (' ', 'h', 'u', 'r', 'r', 'y'): 1, (' ', 'g', 'e', 't'): 1, (' ', 's', 'o', 'm', 'e'): 1, (' ', 'f', 'i', 's', 'h'): 2, (' ', 'f', 'o', 'r'): 1, (' ', 'd', 'i', 'n', 'n', 'e', 'r'): 1, ('!', '\"'): 1, (' ', 's', 'w', 'a', 'm'): 1, (' ', 'f', 'a', 's', 't'): 1, (' ', 'c', 'a', 't', 'c', 'h'): 1}\n",
      "After merging (' ', 'a'): {('\\n',): 8, ('O', 'n', 'c', 'e'): 2, (' ', 'u', 'p', 'o', 'n'): 2, (' a',): 8, (' ', 't', 'i', 'm', 'e'): 2, (' ', 't', 'h', 'e', 'r', 'e'): 2, (' ', 'w', 'a', 's'): 7, (' ', 'l', 'i', 't', 't', 'l', 'e'): 1, (' ', 'b', 'o', 'y'): 1, (' ', 'n', 'a', 'm', 'e', 'd'): 2, (' ', 'B', 'e', 'n'): 7, ('.',): 11, (' ', 'l', 'o', 'v', 'e', 'd'): 2, (' ', 't', 'o'): 3, (' ', 'e', 'x', 'p', 'l', 'o', 'r', 'e'): 1, (' ', 't', 'h', 'e'): 6, (' ', 'w', 'o', 'r', 'l', 'd'): 1, (' a', 'r', 'o', 'u', 'n', 'd'): 1, (' ', 'h', 'i', 'm'): 1, (' ', 'H', 'e'): 4, (' ', 's', 'a', 'w'): 3, (' ', 'm', 'a', 'n', 'y'): 1, (' a', 'm', 'a', 'z', 'i', 'n', 'g'): 5, (' ', 't', 'h', 'i', 'n', 'g', 's'): 1, (',',): 9, (' ', 'l', 'i', 'k', 'e'): 1, (' ', 'b', 'e', 'a', 'u', 't', 'i', 'f', 'u', 'l'): 2, (' ', 'v', 'a', 's', 'e', 's'): 1, (' ', 't', 'h', 'a', 't'): 3, (' ', 'w', 'e', 'r', 'e'): 1, (' ', 'o', 'n'): 1, (' ', 'd', 'i', 's', 'p', 'l', 'a', 'y'): 1, (' ', 'i', 'n'): 3, (' ', 's', 't', 'o', 'r', 'e'): 3, (' ', 'O', 'n', 'e'): 1, (' ', 'd', 'a', 'y'): 2, (' ', 'w', 'a', 'l', 'k', 'i', 'n', 'g'): 1, (' ', 't', 'h', 'r', 'o', 'u', 'g', 'h'): 1, (' ', 'w', 'h', 'e', 'n'): 1, (' ', 'h', 'e'): 3, (' ', 'c', 'a', 'm', 'e'): 1, (' a', 'c', 'r', 'o', 's', 's'): 1, (' ', 'v', 'e', 'r', 'y'): 1, (' ', 's', 'p', 'e', 'c', 'i', 'a', 'l'): 1, (' ', 'v', 'a', 's', 'e'): 6, (' ', 'W', 'h', 'e', 'n'): 1, (' ', 'i', 't'): 5, (' a', 'm', 'a', 'z', 'e', 'd'): 1, ('!',): 4, (' ', ' '): 1, ('H', 'e'): 1, (' ', 's', 'a', 'i', 'd'): 3, (' ', '“'): 2, ('W', 'o', 'w'): 1, (' ', 'i', 's'): 2, (' ', 'r', 'e', 'a', 'l', 'l', 'y'): 1, (' ', 'C', 'a', 'n'): 1, (' ', 'I'): 1, (' ', 'b', 'u', 'y'): 1, ('?', '”'): 1, (' ',): 2, ('T', 'h', 'e'): 1, (' ', 's', 'h', 'o', 'p', 'k', 'e', 'e', 'p', 'e', 'r'): 1, (' ', 's', 'm', 'i', 'l', 'e', 'd'): 1, (' a', 'n', 'd'): 7, ('O', 'f'): 1, (' ', 'c', 'o', 'u', 'r', 's', 'e'): 1, (' ', 'y', 'o', 'u'): 1, (' ', 'c', 'a', 'n'): 2, (' ', 'Y', 'o', 'u'): 1, (' ', 't', 'a', 'k', 'e'): 1, (' ', 'h', 'o', 'm', 'e'): 2, (' ', 's', 'h', 'o', 'w'): 1, (' a', 'l', 'l'): 2, (' ', 'y', 'o', 'u', 'r'): 1, (' ', 'f', 'r', 'i', 'e', 'n', 'd', 's'): 3, (' ', 'h', 'o', 'w'): 3, ('!', '”'): 1, ('S', 'o'): 1, (' ', 't', 'o', 'o', 'k'): 1, (' ', 's', 'o'): 1, (' ', 'p', 'r', 'o', 'u', 'd'): 1, (' ', 'o', 'f'): 1, (' ', 'c', 'a', 'l', 'l', 'e', 'd'): 1, (' ', 'h', 'i', 's'): 3, (' ', 'o', 'v', 'e', 'r'): 1, (' ', 's', 'h', 'o', 'w', 'e', 'd'): 1, (' ', 't', 'h', 'e', 'm'): 1, (' ', 'A', 'l', 'l'): 1, (' ', 't', 'h', 'o', 'u', 'g', 'h', 't'): 1, (' ', 'c', 'o', 'u', 'l', 'd', 'n'): 1, (\"'\", 't'): 1, (' ', 'b', 'e', 'l', 'i', 'e', 'v', 'e'): 1, (' ', 'l', 'u', 'c', 'k', 'y'): 1, ('A', 'n', 'd'): 1, (\"'\", 's'): 2, (' ', 'f', 'o', 'u', 'n', 'd'): 1, (' a', 'n'): 1, ('<', '|'): 1, ('e', 'n', 'd', 'o', 'f', 't', 'e', 'x', 't'): 1, ('|', '>'): 1, (' ', 'r', 'e', 'l', 'i', 'a', 'b', 'l', 'e'): 1, (' ', 'o', 't', 't', 'e', 'r'): 1, (' ', 'O', 'l', 'l', 'i', 'e'): 3, (' ', 'l', 'i', 'v', 'e', 'd'): 1, (' ', 'r', 'i', 'v', 'e', 'r'): 1, (' ', 'w', 'i', 't', 'h'): 1, (' ', 'f', 'a', 'm', 'i', 'l', 'y'): 1, (' ', 'T', 'h', 'e', 'y'): 1, (' ', 'p', 'l', 'a', 'y'): 1, (' ', 's', 'w', 'i', 'm'): 1, (' ', 't', 'o', 'g', 'e', 't', 'h', 'e', 'r'): 1, ('O', 'n', 'e'): 1, (' ', 'm', 'o', 'm'): 1, (' ', '\"'): 1, ('O', 'l', 'l', 'i', 'e'): 1, (' ', 'h', 'u', 'r', 'r', 'y'): 1, (' ', 'g', 'e', 't'): 1, (' ', 's', 'o', 'm', 'e'): 1, (' ', 'f', 'i', 's', 'h'): 2, (' ', 'f', 'o', 'r'): 1, (' ', 'd', 'i', 'n', 'n', 'e', 'r'): 1, ('!', '\"'): 1, (' ', 's', 'w', 'a', 'm'): 1, (' ', 'f', 'a', 's', 't'): 1, (' ', 'c', 'a', 't', 'c', 'h'): 1}\n"
     ]
    }
   ],
   "source": [
    "def merge_pair(vocab, pair_to_merge):\n",
    "    \"\"\"\n",
    "    Takes vocab and a pair like ('s', 't')\n",
    "    Returns new vocab where that pair is merged everywhere\n",
    "    Example: ('n','e','w','e','s','t') → ('n','e','w','e','st') if merging ('s','t')\n",
    "    \"\"\"\n",
    "    new_vocab = {}\n",
    "    \n",
    "    for token, freq in vocab.items():\n",
    "        # We'll build a new version of this token\n",
    "        new_token = []\n",
    "        i = 0\n",
    "        \n",
    "        while i < len(token):\n",
    "            # Check if we can merge at position i\n",
    "            if i < len(token) - 1 and (token[i], token[i + 1]) == pair_to_merge:\n",
    "                # Merge! Combine the two characters\n",
    "                merged_char = token[i] + token[i + 1]\n",
    "                new_token.append(merged_char)\n",
    "                i += 2  # Skip both characters\n",
    "            else:\n",
    "                # Don't merge, just copy\n",
    "                new_token.append(token[i])\n",
    "                i += 1\n",
    "        \n",
    "        # Add to new vocab\n",
    "        new_vocab[tuple(new_token)] = freq\n",
    "    \n",
    "    return new_vocab\n",
    "\n",
    "# Test it!\n",
    "print(f\"\\nBefore merge: {vocab}\")\n",
    "vocab = merge_pair(vocab, best_pair)\n",
    "print(f\"After merging {best_pair}: {vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "283b41da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge 1: '  a' (freq: 26)\n",
      "Merge 2: '  t' (freq: 23)\n",
      "Merge 3: '  s' (freq: 18)\n",
      "Merge 4: 't h' (freq: 17)\n",
      "Merge 5: 'h e' (freq: 17)\n",
      "Merge 6: 'a s' (freq: 15)\n",
      "\n",
      "==================================================\n",
      "Final merges: ['  a', '  t', '  s', 't h', 'h e', 'a s']\n",
      "\n",
      "Final vocabulary:\n",
      "On: 4\n",
      "nc: 2\n",
      "ce: 2\n",
      " u: 2\n",
      "up: 2\n",
      "po: 2\n",
      "on: 3\n",
      " a: 26\n",
      " t: 23\n",
      "ti: 4\n",
      "im: 4\n",
      "me: 8\n",
      "th: 17\n",
      "he: 17\n",
      "er: 10\n",
      "re: 9\n",
      " w: 12\n",
      "wa: 9\n",
      "as: 15\n",
      " l: 6\n",
      "li: 9\n",
      "it: 7\n",
      "tt: 2\n",
      "tl: 1\n",
      "le: 4\n",
      " b: 5\n",
      "bo: 1\n",
      "oy: 1\n",
      " n: 2\n",
      "na: 2\n",
      "am: 11\n",
      "ed: 9\n",
      " B: 7\n",
      "Be: 7\n",
      "en: 13\n",
      "lo: 3\n",
      "ov: 3\n",
      "ve: 7\n",
      "to: 8\n",
      " e: 1\n",
      "ex: 2\n",
      "xp: 1\n",
      "pl: 3\n",
      "or: 6\n",
      "wo: 1\n",
      "rl: 1\n",
      "ld: 2\n",
      "ar: 1\n",
      "ro: 4\n",
      "ou: 10\n",
      "un: 2\n",
      "nd: 14\n",
      " h: 13\n",
      "hi: 5\n",
      " H: 4\n",
      "He: 5\n",
      " s: 18\n",
      "sa: 6\n",
      "aw: 3\n",
      " m: 2\n",
      "ma: 7\n",
      "an: 12\n",
      "ny: 1\n",
      "az: 6\n",
      "zi: 5\n",
      "in: 11\n",
      "ng: 7\n",
      "gs: 1\n",
      "ik: 1\n",
      "ke: 3\n",
      "be: 3\n",
      "ea: 3\n",
      "au: 2\n",
      "ut: 2\n",
      "if: 2\n",
      "fu: 2\n",
      "ul: 3\n",
      " v: 8\n",
      "va: 7\n",
      "se: 8\n",
      "es: 1\n",
      "ha: 3\n",
      "at: 4\n",
      "we: 2\n",
      " o: 4\n",
      " d: 4\n",
      "di: 2\n",
      "is: 8\n",
      "sp: 2\n",
      "la: 2\n",
      "ay: 4\n",
      " i: 10\n",
      "st: 4\n",
      " O: 4\n",
      "ne: 3\n",
      "da: 2\n",
      "al: 6\n",
      "lk: 1\n",
      "ki: 1\n",
      "hr: 1\n",
      "ug: 2\n",
      "gh: 2\n",
      "wh: 1\n",
      " c: 7\n",
      "ca: 5\n",
      "ac: 1\n",
      "cr: 1\n",
      "os: 1\n",
      "ss: 1\n",
      "ry: 2\n",
      "pe: 2\n",
      "ec: 1\n",
      "ci: 1\n",
      "ia: 2\n",
      " W: 1\n",
      "Wh: 1\n",
      "ze: 1\n",
      "  : 1\n",
      "ai: 3\n",
      "id: 3\n",
      " “: 2\n",
      "Wo: 1\n",
      "ow: 6\n",
      " r: 3\n",
      "ll: 9\n",
      "ly: 2\n",
      " C: 1\n",
      "Ca: 1\n",
      " I: 1\n",
      "bu: 1\n",
      "uy: 1\n",
      "?”: 1\n",
      "Th: 2\n",
      "sh: 5\n",
      "ho: 9\n",
      "op: 1\n",
      "pk: 1\n",
      "ee: 1\n",
      "ep: 1\n",
      "sm: 1\n",
      "mi: 2\n",
      "il: 2\n",
      "Of: 1\n",
      "co: 2\n",
      "ur: 3\n",
      "rs: 1\n",
      " y: 2\n",
      "yo: 2\n",
      " Y: 1\n",
      "Yo: 1\n",
      "ta: 1\n",
      "ak: 1\n",
      "om: 4\n",
      " f: 9\n",
      "fr: 3\n",
      "ri: 4\n",
      "ie: 8\n",
      "ds: 3\n",
      "!”: 1\n",
      "So: 1\n",
      "oo: 1\n",
      "ok: 1\n",
      "so: 2\n",
      " p: 2\n",
      "pr: 1\n",
      "ud: 1\n",
      "of: 2\n",
      "em: 1\n",
      " A: 1\n",
      "Al: 1\n",
      "ht: 1\n",
      "dn: 1\n",
      "'t: 1\n",
      "el: 2\n",
      "ev: 1\n",
      "lu: 1\n",
      "uc: 1\n",
      "ck: 1\n",
      "ky: 1\n",
      "An: 1\n",
      "'s: 2\n",
      "fo: 2\n",
      "<|: 1\n",
      "do: 1\n",
      "ft: 1\n",
      "te: 2\n",
      "xt: 1\n",
      "|>: 1\n",
      "ab: 1\n",
      "bl: 1\n",
      "ot: 1\n",
      "Ol: 4\n",
      "iv: 2\n",
      "wi: 2\n",
      "fa: 2\n",
      " T: 1\n",
      "ey: 1\n",
      "sw: 2\n",
      "og: 1\n",
      "ge: 2\n",
      "et: 2\n",
      "mo: 1\n",
      " \": 1\n",
      "hu: 1\n",
      "rr: 1\n",
      " g: 1\n",
      "fi: 2\n",
      "nn: 1\n",
      "!\": 1\n",
      "tc: 1\n",
      "ch: 1\n"
     ]
    }
   ],
   "source": [
    "def train_bpe(token_frequencies, num_merges):\n",
    "    \"\"\"\n",
    "    Main BPE training function.\n",
    "    \n",
    "    Args:\n",
    "        token_frequencies: dict like {\"low\": 5, \"lower\": 2, ...}\n",
    "        num_merges: how many merge operations to perform\n",
    "    \n",
    "    Returns:\n",
    "        merges: list of merge operations performed\n",
    "        final_vocab: the vocabulary after all merges\n",
    "    \"\"\"\n",
    "    # Initialize: convert strings to tuples\n",
    "    vocab = {tuple(list(token)): freq for token, freq in token_frequencies.items()}\n",
    "    \n",
    "    merges = []  # Track the sequence of merges\n",
    "    \n",
    "    for merge_num in range(num_merges):\n",
    "        # Step 1: Count all pairs\n",
    "        pair_freq = get_pair_frequencies(vocab)\n",
    "        \n",
    "        if not pair_freq:\n",
    "            print(f\"No more pairs to merge at step {merge_num}\")\n",
    "            break\n",
    "        \n",
    "        # Step 2: Find best pair\n",
    "        best_pair = get_best_pair(pair_freq)\n",
    "        \n",
    "        # Step 3: Merge it\n",
    "        vocab = merge_pair(vocab, best_pair)\n",
    "        \n",
    "        # Step 4: Record this merge\n",
    "        merge_str = f\"{best_pair[0]} {best_pair[1]}\"\n",
    "        merges.append(merge_str)\n",
    "        \n",
    "        print(f\"Merge {merge_num + 1}: '{merge_str}' (freq: {pair_freq[best_pair]})\")\n",
    "        \n",
    "    return merges, vocab\n",
    "\n",
    "# Run training!\n",
    "merges, final_vocab = train_bpe(pair_freq, num_merges=6)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Final merges:\", merges)\n",
    "print(\"\\nFinal vocabulary:\")\n",
    "for token, freq in final_vocab.items():\n",
    "    print(f\"{''.join(token)}: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d7a6bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge 1: '  a' (freq: 26)\n",
      "Merge 2: '  t' (freq: 23)\n",
      "Merge 3: '  s' (freq: 18)\n",
      "Merge 4: 'h e' (freq: 17)\n",
      "Merge 5: 'a s' (freq: 15)\n",
      "Merge 6: 'n d' (freq: 14)\n",
      "Merge 7: '  w' (freq: 12)\n",
      "Merge 8: 'i n' (freq: 11)\n",
      "Merge 9: 'o u' (freq: 10)\n",
      "Merge 10: '  h' (freq: 10)\n",
      "Merge 11: 'r e' (freq: 9)\n",
      "Merge 12: 'l l' (freq: 9)\n",
      "Merge 13: 'e d' (freq: 9)\n",
      "Merge 14: ' t he' (freq: 9)\n",
      "Merge 15: '  f' (freq: 9)\n",
      "Merge 16: 'i s' (freq: 8)\n",
      "Merge 17: 'i e' (freq: 8)\n",
      "Merge 18: '  v' (freq: 8)\n",
      "Merge 19: 'm a' (freq: 7)\n",
      "Merge 20: 'in g' (freq: 7)\n",
      "Merge 21: 'i t' (freq: 7)\n",
      "Merge 22: 'e n' (freq: 7)\n",
      "Merge 23: 'as e' (freq: 7)\n",
      "Merge 24: 'B en' (freq: 7)\n",
      "Merge 25: ' w as' (freq: 7)\n",
      "Merge 26: ' v ase' (freq: 7)\n",
      "Merge 27: ' a nd' (freq: 7)\n",
      "Merge 28: '  c' (freq: 7)\n",
      "Merge 29: '  Ben' (freq: 7)\n",
      "Merge 30: 'o w' (freq: 6)\n",
      "Merge 31: 'ma z' (freq: 6)\n",
      "Merge 32: 'm e' (freq: 6)\n",
      "Merge 33: 'e r' (freq: 6)\n",
      "Merge 34: ' t h' (freq: 6)\n",
      "Merge 35: ' s a' (freq: 6)\n",
      "Merge 36: ' a maz' (freq: 6)\n",
      "Merge 37: '  l' (freq: 6)\n",
      "Merge 38: 'H e' (freq: 5)\n",
      "Merge 39: ' t o' (freq: 5)\n",
      "Merge 40: ' c a' (freq: 5)\n",
      "Merge 41: ' amaz ing' (freq: 5)\n",
      "Merge 42: '  it' (freq: 5)\n",
      "Merge 43: '  b' (freq: 5)\n",
      "Merge 44: 'o re' (freq: 4)\n",
      "Merge 45: 'll ie' (freq: 4)\n",
      "Merge 46: 'a y' (freq: 4)\n",
      "Merge 47: 'a m' (freq: 4)\n",
      "Merge 48: 'O n' (freq: 4)\n",
      "Merge 49: 'O llie' (freq: 4)\n",
      "Merge 50: '  o' (freq: 4)\n",
      "Merge 51: '  d' (freq: 4)\n",
      "Merge 52: '  He' (freq: 4)\n",
      "Merge 53: 'v ed' (freq: 3)\n",
      "Merge 54: 't ore' (freq: 3)\n",
      "Merge 55: 'r ou' (freq: 3)\n",
      "Merge 56: 'r ie' (freq: 3)\n",
      "Merge 57: 'rie nd' (freq: 3)\n",
      "Merge 58: 'riend s' (freq: 3)\n",
      "Merge 59: 'p l' (freq: 3)\n",
      "Merge 60: 'o me' (freq: 3)\n",
      "Merge 61: 'k e' (freq: 3)\n",
      "Merge 62: 'i d' (freq: 3)\n",
      "Merge 63: 'a t' (freq: 3)\n",
      "Merge 64: ' th at' (freq: 3)\n",
      "Merge 65: ' sa w' (freq: 3)\n",
      "Merge 66: ' sa id' (freq: 3)\n",
      "Merge 67: ' s tore' (freq: 3)\n",
      "Merge 68: ' s h' (freq: 3)\n",
      "Merge 69: ' h ow' (freq: 3)\n",
      "Merge 70: ' h is' (freq: 3)\n",
      "Merge 71: ' f riends' (freq: 3)\n",
      "Merge 72: ' b e' (freq: 3)\n",
      "Merge 73: '  in' (freq: 3)\n",
      "Merge 74: '  he' (freq: 3)\n",
      "Merge 75: '  Ollie' (freq: 3)\n",
      "Merge 76: 'y ou' (freq: 2)\n",
      "Merge 77: 'v er' (freq: 2)\n",
      "Merge 78: 'u t' (freq: 2)\n",
      "Merge 79: 'ut i' (freq: 2)\n",
      "Merge 80: 'uti f' (freq: 2)\n",
      "Merge 81: 'utif u' (freq: 2)\n",
      "Merge 82: 'utifu l' (freq: 2)\n",
      "Merge 83: 'u p' (freq: 2)\n",
      "Merge 84: 'up o' (freq: 2)\n",
      "Merge 85: 'upo n' (freq: 2)\n",
      "Merge 86: 'pl ay' (freq: 2)\n",
      "Merge 87: 'o ved' (freq: 2)\n",
      "Merge 88: 'o r' (freq: 2)\n",
      "Merge 89: 'n am' (freq: 2)\n",
      "Merge 90: 'nam ed' (freq: 2)\n",
      "Merge 91: 'l e' (freq: 2)\n",
      "Merge 92: 'l d' (freq: 2)\n",
      "Merge 93: 'is h' (freq: 2)\n",
      "Merge 94: 'i me' (freq: 2)\n",
      "Merge 95: 'i m' (freq: 2)\n",
      "Merge 96: 'i l' (freq: 2)\n",
      "Merge 97: 'i a' (freq: 2)\n",
      "Merge 98: 'he n' (freq: 2)\n",
      "Merge 99: 'g h' (freq: 2)\n",
      "Merge 100: 'g e' (freq: 2)\n",
      "Merge 101: 'ge t' (freq: 2)\n",
      "Merge 102: 'e x' (freq: 2)\n",
      "Merge 103: 'c e' (freq: 2)\n",
      "Merge 104: 'a utiful' (freq: 2)\n",
      "Merge 105: 'T he' (freq: 2)\n",
      "Merge 106: 'On e' (freq: 2)\n",
      "Merge 107: 'On ce' (freq: 2)\n",
      "Merge 108: '' s' (freq: 2)\n",
      "Merge 109: ' the re' (freq: 2)\n",
      "Merge 110: ' t ime' (freq: 2)\n",
      "Merge 111: ' sh ow' (freq: 2)\n",
      "Merge 112: ' s w' (freq: 2)\n",
      "Merge 113: ' l oved' (freq: 2)\n",
      "Merge 114: ' l i' (freq: 2)\n",
      "Merge 115: ' h ome' (freq: 2)\n",
      "Merge 116: ' f ish' (freq: 2)\n",
      "Merge 117: ' d ay' (freq: 2)\n",
      "Merge 118: ' ca n' (freq: 2)\n",
      "Merge 119: ' c ou' (freq: 2)\n",
      "Merge 120: ' be autiful' (freq: 2)\n",
      "Merge 121: ' a ll' (freq: 2)\n",
      "Merge 122: '  “' (freq: 2)\n",
      "Merge 123: '  you' (freq: 2)\n",
      "Merge 124: '  upon' (freq: 2)\n",
      "Merge 125: '  re' (freq: 2)\n",
      "Merge 126: '  named' (freq: 2)\n",
      "Merge 127: '  is' (freq: 2)\n",
      "Merge 128: '| >' (freq: 1)\n",
      "Merge 129: 'v e' (freq: 1)\n",
      "Merge 130: 'u y' (freq: 1)\n",
      "Merge 131: 'u r' (freq: 1)\n",
      "Merge 132: 'ur r' (freq: 1)\n",
      "Merge 133: 'urr y' (freq: 1)\n",
      "Merge 134: 'u c' (freq: 1)\n",
      "Merge 135: 'uc k' (freq: 1)\n",
      "Merge 136: 'uck y' (freq: 1)\n",
      "Merge 137: 't t' (freq: 1)\n",
      "Merge 138: 'tt er' (freq: 1)\n",
      "Merge 139: 't le' (freq: 1)\n",
      "Merge 140: 't ex' (freq: 1)\n",
      "Merge 141: 'tex t' (freq: 1)\n",
      "Merge 142: 't c' (freq: 1)\n",
      "Merge 143: 'tc h' (freq: 1)\n",
      "Merge 144: 's s' (freq: 1)\n",
      "Merge 145: 's e' (freq: 1)\n",
      "Merge 146: 'rou nd' (freq: 1)\n",
      "Merge 147: 'rou gh' (freq: 1)\n",
      "Merge 148: 'rou d' (freq: 1)\n",
      "Merge 149: 'r se' (freq: 1)\n",
      "Merge 150: 'r o' (freq: 1)\n",
      "Merge 151: 'ro ss' (freq: 1)\n",
      "Merge 152: 'r i' (freq: 1)\n",
      "Merge 153: 'ri ver' (freq: 1)\n",
      "Merge 154: 'pl ore' (freq: 1)\n",
      "Merge 155: 'p roud' (freq: 1)\n",
      "Merge 156: 'p ke' (freq: 1)\n",
      "Merge 157: 'pke e' (freq: 1)\n",
      "Merge 158: 'pkee p' (freq: 1)\n",
      "Merge 159: 'pkeep er' (freq: 1)\n",
      "Merge 160: 'p e' (freq: 1)\n",
      "Merge 161: 'pe c' (freq: 1)\n",
      "Merge 162: 'pec ia' (freq: 1)\n",
      "Merge 163: 'pecia l' (freq: 1)\n",
      "Merge 164: 'ou nd' (freq: 1)\n",
      "Merge 165: 'ou gh' (freq: 1)\n",
      "Merge 166: 'ough t' (freq: 1)\n",
      "Merge 167: 'or ld' (freq: 1)\n",
      "Merge 168: 'o y' (freq: 1)\n",
      "Merge 169: 'o pkeeper' (freq: 1)\n",
      "Merge 170: 'o m' (freq: 1)\n",
      "Merge 171: 'o k' (freq: 1)\n",
      "Merge 172: 'o f' (freq: 1)\n",
      "Merge 173: 'of text' (freq: 1)\n",
      "Merge 174: 'nd oftext' (freq: 1)\n",
      "Merge 175: 'n y' (freq: 1)\n",
      "Merge 176: 'n er' (freq: 1)\n",
      "Merge 177: 'ma ny' (freq: 1)\n",
      "Merge 178: 'm om' (freq: 1)\n",
      "Merge 179: 'm il' (freq: 1)\n",
      "Merge 180: 'mil ed' (freq: 1)\n",
      "Merge 181: 'll y' (freq: 1)\n",
      "Merge 182: 'll ed' (freq: 1)\n",
      "Merge 183: 'ld n' (freq: 1)\n",
      "Merge 184: 'l k' (freq: 1)\n",
      "Merge 185: 'lk ing' (freq: 1)\n",
      "Merge 186: 'l ie' (freq: 1)\n",
      "Merge 187: 'lie ve' (freq: 1)\n",
      "Merge 188: 'l ia' (freq: 1)\n",
      "Merge 189: 'lia b' (freq: 1)\n",
      "Merge 190: 'liab le' (freq: 1)\n",
      "Merge 191: 'it tle' (freq: 1)\n",
      "Merge 192: 'it h' (freq: 1)\n",
      "Merge 193: 'is play' (freq: 1)\n",
      "Merge 194: 'ing s' (freq: 1)\n",
      "Merge 195: 'in ner' (freq: 1)\n",
      "Merge 196: 'il y' (freq: 1)\n",
      "Merge 197: 'he r' (freq: 1)\n",
      "Merge 198: 'get her' (freq: 1)\n",
      "Merge 199: 'ex plore' (freq: 1)\n",
      "Merge 200: 'er y' (freq: 1)\n",
      "Merge 201: 'e re' (freq: 1)\n",
      "Merge 202: 'e ndoftext' (freq: 1)\n",
      "Merge 203: 'c ross' (freq: 1)\n",
      "Merge 204: 'as t' (freq: 1)\n",
      "Merge 205: 'am ily' (freq: 1)\n",
      "Merge 206: 'a n' (freq: 1)\n",
      "Merge 207: 'a lly' (freq: 1)\n",
      "Merge 208: 'a lking' (freq: 1)\n",
      "Merge 209: 'a ke' (freq: 1)\n",
      "Merge 210: 'Y ou' (freq: 1)\n",
      "Merge 211: 'W ow' (freq: 1)\n",
      "Merge 212: 'W hen' (freq: 1)\n",
      "Merge 213: 'The y' (freq: 1)\n",
      "Merge 214: 'S o' (freq: 1)\n",
      "Merge 215: 'O f' (freq: 1)\n",
      "Merge 216: 'C an' (freq: 1)\n",
      "Merge 217: 'A nd' (freq: 1)\n",
      "Merge 218: 'A ll' (freq: 1)\n",
      "Merge 219: '? ”' (freq: 1)\n",
      "Merge 220: '< |' (freq: 1)\n",
      "Merge 221: '' t' (freq: 1)\n",
      "Merge 222: '! ”' (freq: 1)\n",
      "Merge 223: '! \"' (freq: 1)\n",
      "Merge 224: ' you r' (freq: 1)\n",
      "Merge 225: ' w orld' (freq: 1)\n",
      "Merge 226: ' w ith' (freq: 1)\n",
      "Merge 227: ' w hen' (freq: 1)\n",
      "Merge 228: ' w ere' (freq: 1)\n",
      "Merge 229: ' w alking' (freq: 1)\n",
      "Merge 230: ' vase s' (freq: 1)\n",
      "Merge 231: ' v ery' (freq: 1)\n",
      "Merge 232: ' to ok' (freq: 1)\n",
      "Merge 233: ' to gether' (freq: 1)\n",
      "Merge 234: ' the m' (freq: 1)\n",
      "Merge 235: ' th rough' (freq: 1)\n",
      "Merge 236: ' th ought' (freq: 1)\n",
      "Merge 237: ' th ings' (freq: 1)\n",
      "Merge 238: ' t ake' (freq: 1)\n",
      "Merge 239: ' sw im' (freq: 1)\n",
      "Merge 240: ' sw am' (freq: 1)\n",
      "Merge 241: ' show ed' (freq: 1)\n",
      "Merge 242: ' sh opkeeper' (freq: 1)\n",
      "Merge 243: ' s pecial' (freq: 1)\n",
      "Merge 244: ' s ome' (freq: 1)\n",
      "Merge 245: ' s o' (freq: 1)\n",
      "Merge 246: ' s miled' (freq: 1)\n",
      "Merge 247: ' re liable' (freq: 1)\n",
      "Merge 248: ' re ally' (freq: 1)\n",
      "Merge 249: ' o ver' (freq: 1)\n",
      "Merge 250: ' o tter' (freq: 1)\n",
      "Merge 251: ' o n' (freq: 1)\n",
      "Merge 252: ' o f' (freq: 1)\n",
      "Merge 253: ' li ved' (freq: 1)\n",
      "Merge 254: ' li ke' (freq: 1)\n",
      "Merge 255: ' l ucky' (freq: 1)\n",
      "Merge 256: ' l ittle' (freq: 1)\n"
     ]
    }
   ],
   "source": [
    "# Use your actual frequency_table from earlier\n",
    "vocab_from_real_data = {tuple(list(token)): freq \n",
    "                        for token, freq in frequency_table.items()}\n",
    "\n",
    "# Train on it\n",
    "merges, final_vocab = train_bpe(vocab_from_real_data, num_merges=256)  # or however many you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31cb0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bpe(input_path=\"\", vocab_size=1000, special_tokens=[\"<|endoftext|>\"]):\n",
    "    return vocab, merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57b2f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_regex.Scanner object at 0x117611140>\n"
     ]
    }
   ],
   "source": [
    "def decode_utf8(data: bytes) -> str:\n",
    "    return data.decode(\"utf-8\", errors=\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7168f990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
