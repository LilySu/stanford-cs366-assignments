_wandb:
    value:
        cli_version: 0.23.0
        e:
            266n5ixlfls2c8j6vgpzrkb20673yh6b:
                args:
                    - --device
                    - cuda
                    - --exp_name
                    - batch-size-64
                    - --batch_size
                    - "64"
                    - --context_length
                    - "256"
                    - --max_iters
                    - "20000"
                    - --cosine_cycle_iters
                    - "20000"
                    - --lr
                    - "1e-3"
                    - --warmup_iters
                    - "500"
                    - --vocab_size
                    - "50304"
                    - --d_model
                    - "512"
                    - --d_ff
                    - "1344"
                    - --num_layers
                    - "4"
                    - --num_heads
                    - "16"
                    - --rope_theta
                    - "10000"
                    - --train_data
                    - ../data/TinyStoriesV2-GPT4-train.bin
                    - --val_data
                    - ../data/TinyStoriesV2-GPT4-valid.bin
                codePath: cs336_basics/run.py
                codePathLocal: run.py
                cpu_count: 16
                cpu_count_logical: 32
                cudaVersion: "12.9"
                disk:
                    /:
                        total: "21474836480"
                        used: "411725824"
                email: lilyxsu@gmail.com
                executable: /usr/bin/python
                git:
                    commit: 9e77f59a4579e574bab6a53d3410f97c65e6dad2
                    remote: https://github.com/LilySu/stanford-cs366-assignments.git
                gpu: NVIDIA GeForce RTX 4090
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ada
                      cudaCores: 16384
                      memoryTotal: "25757220864"
                      name: NVIDIA GeForce RTX 4090
                      uuid: GPU-d8d879f4-6db5-cd92-1d96-8b0c50d0d5c1
                host: f3ff327fe500
                memory:
                    total: "134123913216"
                os: Linux-6.8.0-64-generic-x86_64-with-glibc2.35
                program: /workspace/stanford-cs366-assignments/cs336_basics/run.py
                python: CPython 3.11.10
                root: /workspace/stanford-cs366-assignments/cs336_basics
                startedAt: "2025-11-27T05:04:25.055824Z"
                writerId: 266n5ixlfls2c8j6vgpzrkb20673yh6b
        m: []
        python_version: 3.11.10
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 13
                - 16
            "4": 3.11.10
            "5": 0.23.0
            "12": 0.23.0
            "13": linux-x86_64
batch_size:
    value: 64
beta1:
    value: 0.9
beta2:
    value: 0.95
checkpoint:
    value: null
context_length:
    value: 256
cosine_cycle_iters:
    value: 20000
d_ff:
    value: 1344
d_model:
    value: 512
debug_subset_tokens:
    value: null
device:
    value: cuda
eval_interval:
    value: 250
eval_iters:
    value: 100
exp_name:
    value: batch-size-64
grad_clip:
    value: 1
log_interval:
    value: 10
lr:
    value: 0.001
max_iters:
    value: 20000
max_new_tokens:
    value: 100
min_lr:
    value: 6e-05
mode:
    value: train
no_wandb:
    value: false
num_heads:
    value: 16
num_layers:
    value: 4
out_dir:
    value: out
prompt:
    value: The meaning of life is
rope_theta:
    value: 10000
save_interval:
    value: 1000
tags:
    value: null
temperature:
    value: 0.8
top_p:
    value: 0.9
train_data:
    value: ../data/TinyStoriesV2-GPT4-train.bin
val_data:
    value: ../data/TinyStoriesV2-GPT4-valid.bin
vocab_size:
    value: 50304
wandb_project:
    value: transformer-training
warmup_iters:
    value: 500
weight_decay:
    value: 0.1
