_wandb:
    value:
        cli_version: 0.23.0
        e:
            8tpivd3bdblj13qelu6ppif9x3fpgm4i:
                args:
                    - --device
                    - cuda
                    - --exp_name
                    - batch-size-128
                    - --batch_size
                    - "128"
                    - --context_length
                    - "256"
                    - --max_iters
                    - "10000"
                    - --cosine_cycle_iters
                    - "10000"
                    - --lr
                    - "1.5e-3"
                    - --warmup_iters
                    - "250"
                    - --vocab_size
                    - "50304"
                    - --d_model
                    - "512"
                    - --d_ff
                    - "1344"
                    - --num_layers
                    - "4"
                    - --num_heads
                    - "16"
                    - --rope_theta
                    - "10000"
                    - --train_data
                    - ../data/TinyStoriesV2-GPT4-train.bin
                    - --val_data
                    - ../data/TinyStoriesV2-GPT4-valid.bin
                codePath: cs336_basics/run.py
                codePathLocal: run.py
                cpu_count: 16
                cpu_count_logical: 32
                cudaVersion: "12.4"
                disk:
                    /:
                        total: "21474836480"
                        used: "411738112"
                email: lilyxsu@gmail.com
                executable: /usr/bin/python
                git:
                    commit: f0e2171adda7879ccf7a365c11e4525e01c50440
                    remote: https://github.com/LilySu/stanford-cs366-assignments.git
                gpu: NVIDIA GeForce RTX 4090
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ada
                      cudaCores: 16384
                      memoryTotal: "25757220864"
                      name: NVIDIA GeForce RTX 4090
                      uuid: GPU-5eccb056-fcff-709f-5827-5461f3e422ee
                host: 344f042360e5
                memory:
                    total: "134236803072"
                os: Linux-6.8.0-40-generic-x86_64-with-glibc2.35
                program: /workspace/stanford-cs366-assignments/cs336_basics/run.py
                python: CPython 3.11.10
                root: /workspace/stanford-cs366-assignments/cs336_basics
                startedAt: "2025-11-27T05:23:13.083466Z"
                writerId: 8tpivd3bdblj13qelu6ppif9x3fpgm4i
        m: []
        python_version: 3.11.10
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 13
                - 16
            "4": 3.11.10
            "5": 0.23.0
            "12": 0.23.0
            "13": linux-x86_64
batch_size:
    value: 128
beta1:
    value: 0.9
beta2:
    value: 0.95
checkpoint:
    value: null
context_length:
    value: 256
cosine_cycle_iters:
    value: 10000
d_ff:
    value: 1344
d_model:
    value: 512
debug_subset_tokens:
    value: null
device:
    value: cuda
eval_interval:
    value: 250
eval_iters:
    value: 100
exp_name:
    value: batch-size-128
grad_clip:
    value: 1
log_interval:
    value: 10
lr:
    value: 0.0015
max_iters:
    value: 10000
max_new_tokens:
    value: 100
min_lr:
    value: 6e-05
mode:
    value: train
no_wandb:
    value: false
num_heads:
    value: 16
num_layers:
    value: 4
out_dir:
    value: out
prompt:
    value: The meaning of life is
rope_theta:
    value: 10000
save_interval:
    value: 1000
tags:
    value: null
temperature:
    value: 0.8
top_p:
    value: 0.9
train_data:
    value: ../data/TinyStoriesV2-GPT4-train.bin
val_data:
    value: ../data/TinyStoriesV2-GPT4-valid.bin
vocab_size:
    value: 50304
wandb_project:
    value: transformer-training
warmup_iters:
    value: 250
weight_decay:
    value: 0.1
